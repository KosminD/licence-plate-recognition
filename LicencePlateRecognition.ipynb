{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c07afd0-d3c9-487a-8b22-5e090841588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import blobconverter\n",
    "import cv2\n",
    "import depthai as dai\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d48463d-3990-4a37-b6e5-fed9f11a8d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline\n",
    "pipeline = dai.Pipeline()\n",
    "\n",
    "# Define sources and outputs\n",
    "cam_rgb = pipeline.create(dai.node.ColorCamera)\n",
    "spatial_det_net = pipeline.create(dai.node.YoloSpatialDetectionNetwork)\n",
    "mono_left = pipeline.create(dai.node.MonoCamera)\n",
    "mono_right = pipeline.create(dai.node.MonoCamera)\n",
    "stereo = pipeline.create(dai.node.StereoDepth)\n",
    "\n",
    "xout_rgb = pipeline.create(dai.node.XLinkOut)\n",
    "xout_vid = pipeline.create(dai.node.XLinkOut)\n",
    "xout_nn = pipeline.create(dai.node.XLinkOut)\n",
    "xout_bbdm = pipeline.create(dai.node.XLinkOut)\n",
    "xout_depth = pipeline.create(dai.node.XLinkOut)\n",
    "\n",
    "xout_rgb.setStreamName(\"rgb\")\n",
    "xout_vid.setStreamName(\"video\")\n",
    "xout_nn.setStreamName(\"detections\")\n",
    "xout_bbdm.setStreamName(\"boundingBoxDepthMapping\")\n",
    "xout_depth.setStreamName(\"depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596fc16a-ee08-44cf-b5c5-6c0393c1500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Properties\n",
    "cam_rgb.setPreviewSize(416, 416)\n",
    "cam_rgb.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)\n",
    "cam_rgb.setVideoSize(960, 960)\n",
    "\n",
    "cam_rgb.setInterleaved(False)\n",
    "cam_rgb.setColorOrder(dai.ColorCameraProperties.ColorOrder.BGR)\n",
    "\n",
    "mono_left.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)\n",
    "mono_left.setBoardSocket(dai.CameraBoardSocket.LEFT)\n",
    "mono_right.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)\n",
    "mono_right.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n",
    "\n",
    "# Setting node configs\n",
    "stereo.setDefaultProfilePreset(dai.node.StereoDepth.PresetMode.HIGH_DENSITY)\n",
    "\n",
    "yolo_blob_path = \"model/frozen_darknet_yolov4_model_openvino_2021.4_5shave.blob\"\n",
    "label_map = [\n",
    "    \"plates\", \"car\"\n",
    "]\n",
    "spatial_det_net.setBlobPath(yolo_blob_path)\n",
    "spatial_det_net.setConfidenceThreshold(0.8)\n",
    "spatial_det_net.input.setBlocking(False)\n",
    "spatial_det_net.setBoundingBoxScaleFactor(0.8)\n",
    "spatial_det_net.setDepthLowerThreshold(100)\n",
    "spatial_det_net.setDepthUpperThreshold(5000)\n",
    "\n",
    "# Yolo specific parameters\n",
    "spatial_det_net.setNumClasses(2)\n",
    "spatial_det_net.setCoordinateSize(4)\n",
    "spatial_det_net.setAnchors([10, 14, 23, 27, 37, 58, 81, 82, 135, 169, 344, 319])\n",
    "spatial_det_net.setAnchorMasks({\"side26\": [1, 2, 3], \"side13\": [3, 4, 5]})\n",
    "spatial_det_net.setIouThreshold(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe46b4a-0d13-4571-a965-046eb66a20a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Licence plate recognition\n",
    "manip = pipeline.createImageManip()\n",
    "manip.setWaitForConfigInput(True)\n",
    "\n",
    "manip_img = pipeline.createXLinkIn()\n",
    "manip_img.setStreamName('manip_img')\n",
    "manip_img.out.link(manip.inputImage)\n",
    "\n",
    "manip_cfg = pipeline.createXLinkIn()\n",
    "manip_cfg.setStreamName('manip_cfg')\n",
    "manip_cfg.out.link(manip.inputConfig)\n",
    "\n",
    "manip_xout = pipeline.createXLinkOut()\n",
    "manip_xout.setStreamName('manip_out')\n",
    "\n",
    "tr_nn = pipeline.createNeuralNetwork()\n",
    "tr_nn.setBlobPath(str(blobconverter.from_zoo(\n",
    "    name='license-plate-recognition-barrier-0007',\n",
    "    shaves=6,\n",
    "    version='2021.4'\n",
    ")))\n",
    "\n",
    "tr_nn_xout = pipeline.createXLinkOut()\n",
    "tr_nn_xout.setStreamName('recognitions')\n",
    "tr_nn.out.link(tr_nn_xout.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ee3991-929f-464e-a412-5708757ee4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linking\n",
    "mono_left.out.link(stereo.left)\n",
    "mono_right.out.link(stereo.right)\n",
    "\n",
    "cam_rgb.preview.link(spatial_det_net.input)\n",
    "cam_rgb.video.link(xout_vid.input)\n",
    "\n",
    "manip.out.link(manip_xout.input)\n",
    "\n",
    "spatial_det_net.passthrough.link(xout_rgb.input)\n",
    "\n",
    "spatial_det_net.out.link(xout_nn.input)\n",
    "spatial_det_net.boundingBoxMapping.link(xout_bbdm.input)\n",
    "\n",
    "stereo.depth.link(spatial_det_net.inputDepth)\n",
    "spatial_det_net.passthroughDepth.link(xout_depth.input)\n",
    "\n",
    "manip.out.link(tr_nn.input)\n",
    "tr_nn.passthrough.link(manip_xout.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5db532-aa0c-4fb1-907a-c0c3190c337c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Connect to device and start pipeline\n",
    "with dai.Device(pipeline) as device:\n",
    "    items = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"<Anhui>\", \"<Beijing>\", \"<Chongqing>\", \"<Fujian>\", \"<Gansu>\",\n",
    "             \"<Guangdong>\", \"<Guangxi>\", \"<Guizhou>\", \"<Hainan>\", \"<Hebei>\", \"<Heilongjiang>\", \"<Henan>\", \"<HongKong>\",\n",
    "             \"<Hubei>\", \"<Hunan>\", \"<InnerMongolia>\", \"<Jiangsu>\", \"<Jiangxi>\", \"<Jilin>\", \"<Liaoning>\", \"<Macau>\",\n",
    "             \"<Ningxia>\", \"<Qinghai>\", \"<Shaanxi>\", \"<Shandong>\", \"<Shanghai>\", \"<Shanxi>\", \"<Sichuan>\", \"<Tianjin>\",\n",
    "             \"<Tibet>\", \"<Xinjiang>\", \"<Yunnan>\", \"<Zhejiang>\", \"<police>\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\",\n",
    "             \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]\n",
    "    # Output queues will be used to get the rgb frames and nn data from the outputs defined above\n",
    "    q_rgb = device.getOutputQueue(name=\"rgb\", maxSize=4, blocking=False)\n",
    "    q_vid = device.getOutputQueue(name=\"video\", maxSize=4, blocking=False)\n",
    "\n",
    "    q_det = device.getOutputQueue(name=\"detections\", maxSize=4, blocking=False)\n",
    "    q_bbdm = device.getOutputQueue(name=\"boundingBoxDepthMapping\", maxSize=4, blocking=False)\n",
    "    q_d = device.getOutputQueue(name=\"depth\", maxSize=4, blocking=False)\n",
    "\n",
    "    q_rec = device.getOutputQueue(name=\"recognitions\", maxSize=4, blocking=False)\n",
    "\n",
    "    q_manip_img = device.getInputQueue('manip_img')\n",
    "    q_manip_cfg = device.getInputQueue('manip_cfg')\n",
    "    q_manip_out = device.getOutputQueue('manip_out')\n",
    "\n",
    "    startTime = time.monotonic()\n",
    "    counter = 0\n",
    "    fps = 0\n",
    "    color = (255, 255, 255)\n",
    "    plates = np.zeros((32, 120, 3))\n",
    "    rec_results = []\n",
    "    while True:\n",
    "        rec_stacked = None\n",
    "        in_prev = q_rgb.get()\n",
    "        in_vid = q_vid.get()\n",
    "        in_det = q_det.get()\n",
    "        depth = q_d.get()\n",
    "        in_rec = q_rec.tryGet()\n",
    "\n",
    "        if in_rec:\n",
    "            rec_data = in_rec.getFirstLayerInt32()\n",
    "            rec_data = rec_data[1:]\n",
    "            rec_img = q_manip_out.get().getCvFrame()\n",
    "            decoded_text = \"\"\n",
    "\n",
    "            for idx in rec_data:\n",
    "                if idx == -1:\n",
    "                    break\n",
    "                decoded_text += items[int(idx)]\n",
    "            rec_results = [(cv2.resize(rec_img, (200, 64)), decoded_text)] + rec_results[:5]\n",
    "\n",
    "            for rec_img, rec_text in rec_results:\n",
    "                rec_placeholder_img = np.zeros((64, 200, 3), np.uint8)\n",
    "                cv2.putText(rec_placeholder_img, rec_text, (5, 25), cv2.FONT_HERSHEY_TRIPLEX, 0.5, (0, 255, 0))\n",
    "                rec_combined = np.hstack((rec_img, rec_placeholder_img))\n",
    "\n",
    "                if rec_stacked is None:\n",
    "                    rec_stacked = rec_combined\n",
    "                else:\n",
    "                    rec_stacked = np.vstack((rec_stacked, rec_combined))\n",
    "\n",
    "            if rec_stacked is not None:\n",
    "                cv2.imshow(\"Recognized plates\", rec_stacked)\n",
    "\n",
    "        frame = in_prev.getCvFrame()\n",
    "        full_frame = in_vid.getCvFrame()\n",
    "        depth_frame = depth.getFrame()  # depth_frame values are in millimeters\n",
    "\n",
    "        depth_frame_color = cv2.normalize(depth_frame, None, 255, 0, cv2.NORM_INF, cv2.CV_8UC1)\n",
    "        depth_frame_color = cv2.equalizeHist(depth_frame_color)\n",
    "        depth_frame_color = cv2.applyColorMap(depth_frame_color, cv2.COLORMAP_HOT)\n",
    "\n",
    "        counter += 1\n",
    "        current_time = time.monotonic()\n",
    "\n",
    "        if (current_time - startTime) > 1:\n",
    "            fps = counter / (current_time - startTime)\n",
    "            counter = 0\n",
    "            startTime = current_time\n",
    "\n",
    "        detections = in_det.detections\n",
    "\n",
    "        if len(detections) != 0:\n",
    "            boundingBoxMapping = q_bbdm.get()\n",
    "            roiDatas = boundingBoxMapping.getConfigData()\n",
    "\n",
    "            for roiData in roiDatas:\n",
    "                roi = roiData.roi\n",
    "                roi = roi.denormalize(depth_frame_color.shape[1], depth_frame_color.shape[0])\n",
    "                top_left = roi.topLeft()\n",
    "                bottom_right = roi.bottomRight()\n",
    "                xmin = int(top_left.x)\n",
    "                ymin = int(top_left.y)\n",
    "                xmax = int(bottom_right.x)\n",
    "                ymax = int(bottom_right.y)\n",
    "\n",
    "                cv2.rectangle(depth_frame_color, (xmin, ymin), (xmax, ymax), color, cv2.FONT_HERSHEY_SCRIPT_SIMPLEX)\n",
    "\n",
    "        # If the frame is available, draw bounding boxes on it and show the frame\n",
    "        height = frame.shape[0]\n",
    "        width = frame.shape[1]\n",
    "        full_height = full_frame.shape[0]\n",
    "        full_width = full_frame.shape[1]\n",
    "        idx = 0\n",
    "        plates_list = []\n",
    "\n",
    "        for detection in detections:\n",
    "            # Denormalize bounding box\n",
    "            x1 = int(detection.xmin * width)\n",
    "            x2 = int(detection.xmax * width)\n",
    "            y1 = int(detection.ymin * height)\n",
    "            y2 = int(detection.ymax * height)\n",
    "            try:\n",
    "                label = label_map[detection.label]\n",
    "            except:\n",
    "                label = detection.label\n",
    "\n",
    "            if label == \"plates\":\n",
    "                rr = dai.RotatedRect()\n",
    "                x_center = int((detection.xmin + (detection.xmax - detection.xmin) / 2) * full_width)\n",
    "                y_center = int((detection.ymin + (detection.ymax - detection.ymin) / 2) * full_height)\n",
    "                x_size = int((detection.xmax - detection.xmin) * full_width)\n",
    "                y_size = int((detection.ymax - detection.ymin) * full_height)\n",
    "\n",
    "                rr.center.x = x_center\n",
    "                rr.center.y = y_center\n",
    "                rr.size.width = x_size\n",
    "                rr.size.height = y_size\n",
    "\n",
    "                cfg = dai.ImageManipConfig()\n",
    "                cfg.setCropRotatedRect(rr, False)\n",
    "                cfg.setResize(94, 24)\n",
    "                # Send frame and config to device\n",
    "                if idx == 0:\n",
    "                    imgFrame = dai.ImgFrame()\n",
    "                    imgFrame.setData(full_frame.transpose(2, 0, 1).flatten())\n",
    "                    imgFrame.setType(dai.ImgFrame.Type.BGR888p)\n",
    "                    imgFrame.setWidth(full_width)\n",
    "                    imgFrame.setHeight(full_height)\n",
    "                    q_manip_img.send(imgFrame)\n",
    "                    idx = 1\n",
    "                else:\n",
    "                    cfg.setReusePreviousImage(True)\n",
    "                q_manip_cfg.send(cfg)\n",
    "\n",
    "                transformed = q_manip_out.get().getCvFrame()\n",
    "                plates_list.append(transformed)\n",
    "            cv2.putText(frame, str(label), (x1 + 10, y1 + 20), cv2.FONT_HERSHEY_TRIPLEX, 0.5, (0, 255, 0))\n",
    "            cv2.putText(frame, \"{:.2f}\".format(detection.confidence * 100), (x1 + 10, y1 + 35), cv2.FONT_HERSHEY_TRIPLEX, 0.5, (0, 255, 0))\n",
    "            cv2.putText(frame, f\"X: {int(detection.spatialCoordinates.x)} mm\", (x1 + 10, y1 + 50), cv2.FONT_HERSHEY_TRIPLEX, 0.5, (0, 255, 0))\n",
    "            cv2.putText(frame, f\"Y: {int(detection.spatialCoordinates.y)} mm\", (x1 + 10, y1 + 65), cv2.FONT_HERSHEY_TRIPLEX, 0.5, (0, 255, 0))\n",
    "            cv2.putText(frame, f\"Z: {int(detection.spatialCoordinates.z)} mm\", (x1 + 10, y1 + 80), cv2.FONT_HERSHEY_TRIPLEX, 0.5, (0, 255, 0))\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, cv2.FONT_HERSHEY_SIMPLEX)\n",
    "\n",
    "        cv2.putText(frame, \"NN fps: {:.2f}\".format(fps), (2, frame.shape[0] - 4), cv2.FONT_HERSHEY_TRIPLEX, 0.4, color)\n",
    "        if len(plates_list) > 0:\n",
    "            plates_img = cv2.vconcat(plates_list)\n",
    "            cv2.imshow(\"plates\", plates_img)\n",
    "        cv2.imshow(\"depth\", depth_frame_color)\n",
    "        cv2.imshow(\"rgb\", frame)\n",
    "        cv2.imshow(\"full_frame\", full_frame)\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48deab4a-1fff-43e9-9f7e-671ed4557893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ocr]",
   "language": "python",
   "name": "conda-env-ocr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
